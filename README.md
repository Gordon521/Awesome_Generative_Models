# Awesome_Generative_Models
Awesome Generative Models is a curated repository tracking progress in generative AI, serving as a resource for state-of-the-art papers, code, and datasets. *(The project is under active development, and contributions are warmly welcome!)*
# Table of Contents
- [Papers](#papers)
  - [Surveys](#surveys)
  - [Foundation Models](#foundation-models)
  - [Dataset](#datasets)
  - [Tokenizer](#Tokenizer)
  - [Diffusion models](#diffusion-models)
    - [paper list](#paper-list)
  - [Autogressive models](#autogressive-models)
    - [paper list](#paper-list-1)
## Surveys
* A Survey on Generative Diffusion Models. [[Paper]](https://ieeexplore.ieee.org/abstract/document/10419041)
* Personalized Image Generation with Deep Generative Models: A Decade Survey. [[Paper]](https://arxiv.org/abs/2502.13081)
## Foundation Models
- `LDM` **High-Resolution Image Synthesis with Latent Diffusion Models.**
  [[Paper](https://arxiv.org/abs/2112.10752)] [[Code](https://github.com/CompVis/latent-diffusion)]
- `DALL·E 1` **Zero-Shot Text-to-Image Generation.**
  [[Paper](https://arxiv.org/abs/2102.12092)] [[Code](https://github.com/openai/DALL-E)]
- `DALL·E 2` **Hierarchical Text-Conditional Image Generation with CLIP Latents.** 
  [[Paper](https://arxiv.org/abs/2204.06125)] 
- `Imagen` **Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding.**
  [[Paper](https://arxiv.org/abs/2205.11487)]
- `Parti` **Scaling Autoregressive Models for Content-Rich Text-to-Image Generation.**
  [[Paper](https://arxiv.org/abs/2206.10789)]
- `StyleGAN` **A Style-Based Generator Architecture for Generative Adversarial Networks.**
  [[Paper](https://arxiv.org/abs/1812.04948)] [[Code](https://github.com/NVlabs/stylegan)]
- `StyleGAN 2` **Analyzing and Improving the Image Quality of StyleGAN.**
  [[Paper](https://arxiv.org/abs/1912.04958)] [[Code](https://github.com/NVlabs/stylegan2)]
- `StyleGAN 3` **Alias-Free Generative Adversarial Networks.**
  [[Paper](https://arxiv.org/abs/2106.12423)] [[Code](https://github.com/NVlabs/stylegan3)]​
## Dataset
## Tokenizer
- `VAE` **Auto-Encoding Variational Bayes**
  [[Paper](https://arxiv.org/abs/1312.6114)]
- `VQVAE` **Neural Discrete Representation Learning**
  [[Paper](https://arxiv.org/abs/1711.00937)]
- `VQVAE 2` **Generating Diverse High-Fidelity Images with VQ-VAE-2**
  [[Paper](https://arxiv.org/abs/1906.00446)]
- `VAVAE` **Neural Discrete Representation Learning**
  [[Paper](https://arxiv.org/abs/2412.04852)] [[Code](https://github.com/hustvl/LightningDiT)]
- `titok` **An Image is Worth 32 Tokens for Reconstruction and Generation**
  [[Paper](https://arxiv.org/abs/2406.07550)] [[Code](https://github.com/bytedance/1d-tokenizer)]
- `tatitok` **Democratizing Text-to-Image Masked Generative Models with Compact Text-Aware One-Dimensional Tokens**
  [[Paper](https://arxiv.org/abs/2501.07730)] [[Code](https://github.com/bytedance/1d-tokenizer)]
## Diffusion models
Please also see a LaTeX table (located in xxx) containing a curated list of references from this repository for your convenience in citing directly within your papers.
(To be revised)
| Methods | Paper | Pub | Params | Resolusion | Steps | gFID | Latency(s) | Throughput(images/s) | Code |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
### Paper list
## Autogressive models
Please also see a LaTeX table (located in xxx) containing a curated list of references from this repository for your convenience in citing directly within your papers.
(To be revised)
| Methods | Paper | Pub | Params | Resolusion | Steps | gFID | Latency(s) | Throughput(images/s) | Code |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
### Paper list
